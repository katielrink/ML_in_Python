{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Assignment Four: The Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load, Split, and Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data\n",
    "Save data into a dataframe. Remove any obervations with missing data. Encode string data as integers\n",
    "\n",
    "**Data Set** : US Census Data - https://www.kaggle.com/muonneutrino/us-census-demographic-data/dataLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74001 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      "TractId             74001 non-null int64\n",
      "State               74001 non-null object\n",
      "County              74001 non-null object\n",
      "TotalPop            74001 non-null int64\n",
      "Men                 74001 non-null int64\n",
      "Women               74001 non-null int64\n",
      "Hispanic            73305 non-null float64\n",
      "White               73305 non-null float64\n",
      "Black               73305 non-null float64\n",
      "Native              73305 non-null float64\n",
      "Asian               73305 non-null float64\n",
      "Pacific             73305 non-null float64\n",
      "VotingAgeCitizen    74001 non-null int64\n",
      "Income              72885 non-null float64\n",
      "IncomeErr           72885 non-null float64\n",
      "IncomePerCap        73256 non-null float64\n",
      "IncomePerCapErr     73256 non-null float64\n",
      "Poverty             73159 non-null float64\n",
      "ChildPoverty        72891 non-null float64\n",
      "Professional        73190 non-null float64\n",
      "Service             73190 non-null float64\n",
      "Office              73190 non-null float64\n",
      "Construction        73190 non-null float64\n",
      "Production          73190 non-null float64\n",
      "Drive               73200 non-null float64\n",
      "Carpool             73200 non-null float64\n",
      "Transit             73200 non-null float64\n",
      "Walk                73200 non-null float64\n",
      "OtherTransp         73200 non-null float64\n",
      "WorkAtHome          73200 non-null float64\n",
      "MeanCommute         73055 non-null float64\n",
      "Employed            74001 non-null int64\n",
      "PrivateWork         73190 non-null float64\n",
      "PublicWork          73190 non-null float64\n",
      "SelfEmployed        73190 non-null float64\n",
      "FamilyWork          73190 non-null float64\n",
      "Unemployment        73191 non-null float64\n",
      "dtypes: float64(29), int64(6), object(2)\n",
      "memory usage: 20.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TractId</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>1845</td>\n",
       "      <td>899</td>\n",
       "      <td>946</td>\n",
       "      <td>2.4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>24.5</td>\n",
       "      <td>881</td>\n",
       "      <td>74.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>2172</td>\n",
       "      <td>1167</td>\n",
       "      <td>1005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>852</td>\n",
       "      <td>75.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>3385</td>\n",
       "      <td>1533</td>\n",
       "      <td>1852</td>\n",
       "      <td>8.0</td>\n",
       "      <td>61.4</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>1482</td>\n",
       "      <td>73.3</td>\n",
       "      <td>21.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>4267</td>\n",
       "      <td>2001</td>\n",
       "      <td>2266</td>\n",
       "      <td>9.6</td>\n",
       "      <td>80.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>1849</td>\n",
       "      <td>75.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga County</td>\n",
       "      <td>9965</td>\n",
       "      <td>5054</td>\n",
       "      <td>4911</td>\n",
       "      <td>0.9</td>\n",
       "      <td>77.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4787</td>\n",
       "      <td>71.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73996</th>\n",
       "      <td>72153750501</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Yauco Municipio</td>\n",
       "      <td>6011</td>\n",
       "      <td>3035</td>\n",
       "      <td>2976</td>\n",
       "      <td>99.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>26.9</td>\n",
       "      <td>1576</td>\n",
       "      <td>59.2</td>\n",
       "      <td>33.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73997</th>\n",
       "      <td>72153750502</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Yauco Municipio</td>\n",
       "      <td>2342</td>\n",
       "      <td>959</td>\n",
       "      <td>1383</td>\n",
       "      <td>99.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>25.3</td>\n",
       "      <td>666</td>\n",
       "      <td>58.4</td>\n",
       "      <td>35.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73998</th>\n",
       "      <td>72153750503</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Yauco Municipio</td>\n",
       "      <td>2218</td>\n",
       "      <td>1001</td>\n",
       "      <td>1217</td>\n",
       "      <td>99.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>560</td>\n",
       "      <td>57.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73999</th>\n",
       "      <td>72153750601</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Yauco Municipio</td>\n",
       "      <td>4380</td>\n",
       "      <td>1964</td>\n",
       "      <td>2416</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>1062</td>\n",
       "      <td>67.7</td>\n",
       "      <td>30.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74000</th>\n",
       "      <td>72153750602</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Yauco Municipio</td>\n",
       "      <td>3001</td>\n",
       "      <td>1343</td>\n",
       "      <td>1658</td>\n",
       "      <td>99.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>21.6</td>\n",
       "      <td>759</td>\n",
       "      <td>75.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74001 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           TractId        State           County  TotalPop   Men  Women  \\\n",
       "0       1001020100      Alabama   Autauga County      1845   899    946   \n",
       "1       1001020200      Alabama   Autauga County      2172  1167   1005   \n",
       "2       1001020300      Alabama   Autauga County      3385  1533   1852   \n",
       "3       1001020400      Alabama   Autauga County      4267  2001   2266   \n",
       "4       1001020500      Alabama   Autauga County      9965  5054   4911   \n",
       "...            ...          ...              ...       ...   ...    ...   \n",
       "73996  72153750501  Puerto Rico  Yauco Municipio      6011  3035   2976   \n",
       "73997  72153750502  Puerto Rico  Yauco Municipio      2342   959   1383   \n",
       "73998  72153750503  Puerto Rico  Yauco Municipio      2218  1001   1217   \n",
       "73999  72153750601  Puerto Rico  Yauco Municipio      4380  1964   2416   \n",
       "74000  72153750602  Puerto Rico  Yauco Municipio      3001  1343   1658   \n",
       "\n",
       "       Hispanic  White  Black  Native  ...  Walk  OtherTransp  WorkAtHome  \\\n",
       "0           2.4   86.3    5.2     0.0  ...   0.5          0.0         2.1   \n",
       "1           1.1   41.6   54.5     0.0  ...   0.0          0.5         0.0   \n",
       "2           8.0   61.4   26.5     0.6  ...   1.0          0.8         1.5   \n",
       "3           9.6   80.3    7.1     0.5  ...   1.5          2.9         2.1   \n",
       "4           0.9   77.5   16.4     0.0  ...   0.8          0.3         0.7   \n",
       "...         ...    ...    ...     ...  ...   ...          ...         ...   \n",
       "73996      99.7    0.3    0.0     0.0  ...   0.5          0.0         3.6   \n",
       "73997      99.1    0.9    0.0     0.0  ...   0.0          0.0         1.3   \n",
       "73998      99.5    0.2    0.0     0.0  ...   3.4          0.0         3.4   \n",
       "73999     100.0    0.0    0.0     0.0  ...   0.0          0.0         0.0   \n",
       "74000      99.2    0.8    0.0     0.0  ...   4.9          0.0         8.9   \n",
       "\n",
       "       MeanCommute  Employed  PrivateWork  PublicWork  SelfEmployed  \\\n",
       "0             24.5       881         74.2        21.2           4.5   \n",
       "1             22.2       852         75.9        15.0           9.0   \n",
       "2             23.1      1482         73.3        21.1           4.8   \n",
       "3             25.9      1849         75.8        19.7           4.5   \n",
       "4             21.0      4787         71.4        24.1           4.5   \n",
       "...            ...       ...          ...         ...           ...   \n",
       "73996         26.9      1576         59.2        33.8           7.0   \n",
       "73997         25.3       666         58.4        35.4           6.2   \n",
       "73998         23.5       560         57.5        34.5           8.0   \n",
       "73999         24.1      1062         67.7        30.4           1.9   \n",
       "74000         21.6       759         75.9        19.1           5.0   \n",
       "\n",
       "       FamilyWork  Unemployment  \n",
       "0             0.0           4.6  \n",
       "1             0.0           3.4  \n",
       "2             0.7           4.7  \n",
       "3             0.0           6.1  \n",
       "4             0.0           2.3  \n",
       "...           ...           ...  \n",
       "73996         0.0          20.8  \n",
       "73997         0.0          26.3  \n",
       "73998         0.0          23.0  \n",
       "73999         0.0          29.5  \n",
       "74000         0.0          17.9  \n",
       "\n",
       "[74001 rows x 37 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import all necessary utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "\n",
    "#Loading the dataset\n",
    "data = pd.read_csv('../Data/acs2017_census_tract_data.csv', low_memory=False)\n",
    "\n",
    "#Showing data\n",
    "data.info()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72718 entries, 0 to 74000\n",
      "Data columns (total 37 columns):\n",
      "TractId             72718 non-null int64\n",
      "State               72718 non-null int64\n",
      "County              72718 non-null int64\n",
      "TotalPop            72718 non-null int64\n",
      "Men                 72718 non-null int64\n",
      "Women               72718 non-null int64\n",
      "Hispanic            72718 non-null float64\n",
      "White               72718 non-null float64\n",
      "Black               72718 non-null float64\n",
      "Native              72718 non-null float64\n",
      "Asian               72718 non-null float64\n",
      "Pacific             72718 non-null float64\n",
      "VotingAgeCitizen    72718 non-null int64\n",
      "Income              72718 non-null float64\n",
      "IncomeErr           72718 non-null float64\n",
      "IncomePerCap        72718 non-null float64\n",
      "IncomePerCapErr     72718 non-null float64\n",
      "Poverty             72718 non-null float64\n",
      "ChildPoverty        72718 non-null float64\n",
      "Professional        72718 non-null float64\n",
      "Service             72718 non-null float64\n",
      "Office              72718 non-null float64\n",
      "Construction        72718 non-null float64\n",
      "Production          72718 non-null float64\n",
      "Drive               72718 non-null float64\n",
      "Carpool             72718 non-null float64\n",
      "Transit             72718 non-null float64\n",
      "Walk                72718 non-null float64\n",
      "OtherTransp         72718 non-null float64\n",
      "WorkAtHome          72718 non-null float64\n",
      "MeanCommute         72718 non-null float64\n",
      "Employed            72718 non-null int64\n",
      "PrivateWork         72718 non-null float64\n",
      "PublicWork          72718 non-null float64\n",
      "SelfEmployed        72718 non-null float64\n",
      "FamilyWork          72718 non-null float64\n",
      "Unemployment        72718 non-null float64\n",
      "dtypes: float64(29), int64(8)\n",
      "memory usage: 21.1 MB\n"
     ]
    }
   ],
   "source": [
    "#Remove all rows with null values\n",
    "data.dropna(inplace=True);\n",
    "\n",
    "#Convert all String Values to Integers\n",
    "data[['State', 'County']] = data[['State', 'County']].apply(lambda x: pd.factorize(x)[0])\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting Data\n",
    "Split the dataset into 80% training and 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data matrix: (72718, 36)\n",
      "The shape of the target variable: (72718,)\n"
     ]
    }
   ],
   "source": [
    "# Creating our data matrix (X) and our target variable (y) that we will work on from the dataframe we have\n",
    "X = data[['TractId', 'State', 'County', 'TotalPop', 'Men', 'Women', 'Hispanic',\n",
    "       'White', 'Black', 'Native', 'Asian', 'Pacific', 'VotingAgeCitizen',\n",
    "       'Income', 'IncomeErr', 'IncomePerCap', 'IncomePerCapErr', 'Poverty',\n",
    "       'Professional', 'Service', 'Office', 'Construction',\n",
    "       'Production', 'Drive', 'Carpool', 'Transit', 'Walk', 'OtherTransp',\n",
    "       'WorkAtHome', 'MeanCommute', 'Employed', 'PrivateWork', 'PublicWork',\n",
    "       'SelfEmployed', 'FamilyWork', 'Unemployment']].to_numpy()\n",
    "y = data.ChildPoverty.to_numpy()\n",
    "print(\"The shape of the data matrix: \" + str(X.shape))\n",
    "print(\"The shape of the target variable: \" + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training matrix and target shapes: (58174, 36) & (58174,)\n",
      "The testing matrix and target shapes: (14544, 36) & (14544,)\n"
     ]
    }
   ],
   "source": [
    "# Dividing the data into training and testing data using an 80% training and 20% testing split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.copy(), y.copy(), test_size=0.2, random_state=0)\n",
    "print(\"The training matrix and target shapes: \" + str(X_train.shape)+ ' & ' + str(y_train.shape))\n",
    "print(\"The testing matrix and target shapes: \" + str(X_test.shape)+ ' & ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing Data\n",
    "Balance the dataset so there are the same number of instances within each class. Explain the reasoning of which method you chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#original split into 4 classes : low, average, high, and extreme poverty\n",
    "#Graph general boxplot to see break-up\n",
    "plt.boxplot(y_train)\n",
    "plt.show()\n",
    "\n",
    "#Calculate Quartiles\n",
    "Q1, median, Q3 = np.percentile(np.asarray(y_train), [25, 50, 75])\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "loval = Q1 - 1.5 * IQR\n",
    "hival = Q3 + 1.5 * IQR\n",
    "\n",
    "#Calculate Classes\n",
    "#Low is less than Q1, Average is between Q1-Q3, High is between Q3 and highval, extreme are outliers above highval\n",
    "def classify(row):\n",
    "    if row['ChildPoverty'] < Q1:\n",
    "        val = 0\n",
    "    elif row['ChildPoverty'] < Q3:\n",
    "        val = 1\n",
    "    elif row['ChildPoverty'] < hival:\n",
    "        val = 2\n",
    "    else : \n",
    "        val = 3\n",
    "    return val\n",
    "\n",
    "data['cp_class'] = data.apply(classify, axis=1)\n",
    "\n",
    "#Split again to convert y_train and y_test to classes\n",
    "y = data.cp_class.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.copy(), y.copy(), test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 4 artists>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make sure there are equal number of instances in each class\n",
    "#Graph of balance\n",
    "plt.bar(np.unique(y_train), np.unique(y_train, return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a6dd773483ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Making an instance of SMOTE class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# For oversampling of minority class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "# Making an instance of SMOTE class \n",
    "# For oversampling of minority class\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "  \n",
    "# Fit predictor (x variable)\n",
    "# and target (y variable) using fit_resample()\n",
    "X_OverSmote, Y_OverSmote = smote.fit_resample(X.copy(), y.copy())\n",
    "plt.bar(np.unique(Y_OverSmote), np.unique(Y_OverSmote, return_counts=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Should balancing of the dataset be done for both the training and testing set? Explain.** <br/>\n",
    "Balancing should be done on just the training dataset and not the testing set. The model has already adjusted for imbalance to have equal awareness of the underrepresented classes, so it does not matter what data it is tested against. Additionally, while we want the data we train on to minimize biases, we do want the data we test against to be a reflection of the true values of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-Layer Perceptron\n",
    "Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Do not normalize or one-hot encode the data (not yet). Be sure that training converges by graphing the loss function versus the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerPerceptronBase(object):\n",
    "    def __init__(self, n_hidden=30,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        W1_num_elems = (self.n_features_)*self.n_hidden\n",
    "        W1 = np.random.uniform(-1.0, 1.0, size=W1_num_elems)\n",
    "        W1 = W1.reshape(self.n_hidden, self.n_features_) # reshape to be W\n",
    "        b1 = np.zeros((self.n_hidden, 1))\n",
    "        \n",
    "        W2_num_elems = (self.n_hidden)*self.n_output_\n",
    "        W2 = np.random.uniform(-1.0, 1.0, size=W2_num_elems)\n",
    "        W2 = W2.reshape(self.n_output_, self.n_hidden)\n",
    "        b2 = np.zeros((self.n_output_, 1))\n",
    "        \n",
    "        return W1, W2, b1, b2\n",
    "    \n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        \"\"\"Use scipy.special.expit to avoid overflow\"\"\"\n",
    "        # 1.0 / (1.0 + np.exp(-z))\n",
    "        return expit(z)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, W1, W2):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        return (lambda_) * np.sqrt(np.mean(W1 ** 2) + np.mean(W2 ** 2))\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,W1,W2):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, W1, W2)\n",
    "        return cost + L2_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerPerceptron(TwoLayerPerceptronBase):\n",
    "    def _feedforward(self, X, W1, W2, b1, b2):\n",
    "        \"\"\"Compute feedforward step\n",
    "        -----------\n",
    "        X : Input layer with original features.\n",
    "        W1: Weight matrix for input layer -> hidden layer.\n",
    "        W2: Weight matrix for hidden layer -> output layer.\n",
    "        ----------\n",
    "        a1-a3 : activations into layer (or output layer)\n",
    "        z1-z2 : layer inputs \n",
    "\n",
    "        \"\"\"\n",
    "        A1 = X.T\n",
    "        Z1 = W1 @ A1 + b1\n",
    "        A2 = self._sigmoid(Z1)\n",
    "        Z2 = W2 @ A2 + b2\n",
    "        A3 = self._sigmoid(Z2)\n",
    "        return A1, Z1, A2, Z2, A3\n",
    "    \n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # need to vectorize this computation!\n",
    "        # See additional code and derivation below!\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        _, _, _, _, A3 = self._feedforward(X, self.W1, self.W2, self.b1, self.b2)\n",
    "        y_pred = np.argmax(A3, axis=0)\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data.\"\"\"\n",
    "        \n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.W1, self.W2, self.b1, self.b2 = self._initialize_weights()\n",
    "\n",
    "        self.cost_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            # feedforward all instances\n",
    "            A1, Z1, A2, Z2, A3 = self._feedforward(X_data,self.W1,self.W2, self.b1, self.b2)\n",
    "            \n",
    "            cost = self._cost(A3,Y_enc,self.W1,self.W2)\n",
    "            self.cost_.append(cost)\n",
    "\n",
    "            # compute gradient via backpropagation\n",
    "            gradW1, gradW2, gradb1, gradb2 = self._get_gradient(A1=A1, A2=A2, A3=A3, Z1=Z1, Z2=Z2, Y_enc=Y_enc,\n",
    "                                              W1=self.W1, W2=self.W2)\n",
    "\n",
    "            self.W1 -= self.eta * gradW1\n",
    "            self.W2 -= self.eta * gradW2\n",
    "            self.b1 -= self.eta * gradb1\n",
    "            self.b2 -= self.eta * gradb2\n",
    "            \n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerPerceptronVectorized(TwoLayerPerceptron):\n",
    "    # just need a different gradient calculation\n",
    "    def _get_gradient(self, A1, A2, A3, Z1, Z2, Y_enc, W1, W2):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        V2 = -2*(Y_enc-A3)*A3*(1-A3)\n",
    "        V1 = A2*(1-A2)*(W2.T @ V2)\n",
    "        \n",
    "        gradW2 = V2 @ A2.T\n",
    "        gradW1 = V1 @ A1.T\n",
    "        \n",
    "        gradb2 = np.sum(V2, axis=1).reshape((-1,1))\n",
    "        gradb1 = np.sum(V1, axis=1).reshape((-1,1))\n",
    "        \n",
    "        \n",
    "        # regularize weights that are not bias terms\n",
    "        gradW1 += W1 * self.l2_C * 2\n",
    "        gradW2 += W2 * self.l2_C * 2 \n",
    "\n",
    "        return gradW1, gradW2, gradb1, gradb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_two_layer_perceptron(X_train, y_train, X_test, y_test):\n",
    "    params = dict(n_hidden=50, \n",
    "              C=0.1, # tradeoff L2 regularizer\n",
    "              epochs=400, # iterations\n",
    "              eta=0.001,  # learning rate\n",
    "              random_state=1)\n",
    "\n",
    "    nn = TwoLayerPerceptronVectorized(**params)\n",
    "\n",
    "    nn.fit(X_train, y_train, print_progress=50)\n",
    "    yhat = nn.predict(X_test)\n",
    "    print('Accuracy:',accuracy_score(y_test,yhat))\n",
    "\n",
    "    plt.plot(range(len(nn.cost_)), nn.cost_)\n",
    "    plt.ylabel('Cost')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 400/400"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5011688668866887\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi41LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvSM8oowAAIABJREFUeJzt3X+QnVd93/H3Z39Jq7UsyVg2RJKRSJSkkMHGLKKJA7GhNjI/qtLSWJA0GUqrMbUbkkwJ8jDDpE1nGur+gNRKNAp1nYQfmk5AtkoU25QAJikBrUC2JRvBIoy1CNAKaWVLu2h3pW//eM7dfXR1d3V3tc/eI/nzmtnZe899nrvffWa0H53znHuOIgIzM7PctLW6ADMzs0YcUGZmliUHlJmZZckBZWZmWXJAmZlZlhxQZmaWJQeUmZllyQFlZmZZckCZmVmWOlpdwFy6+uqrY/Xq1a0uw8zMprFnz56jEbH8QsddVgG1evVq+vr6Wl2GmZlNQ9L3mjnOQ3xmZpYlB5SZmWWp0oCStF7SAUn9kjY3eH2JpP8j6XFJ+yW9u/TaM5KelLRXksftzMxeYCq7ByWpHdgC3AoMALsl7YyIp0qH3QU8FRFvk7QcOCDpExExml6/JSKOVlWjmZnlq8oe1DqgPyIOpsDZDmyoOyaAxZIEXAEcA8YrrMnMzC4RVQbUCuBQ6flAaiu7D/gHwGHgSeB9EXE2vRbAo5L2SNpUYZ1mZpahKgNKDdrqt+99E7AX+CngBuA+SVem126KiBuB24G7JL2+4Q+RNknqk9Q3ODg4R6WbmVmrVRlQA8Cq0vOVFD2lsncDn4lCP/Bd4OcBIuJw+n4E2EExZHieiNgWEb0R0bt8+QU/9zWtQ8eGeexbgzw5cIKB48OcOj1ORH2mmpnZfKjyg7q7gbWS1gDfBzYC76o75lngjcCXJV0L/BxwUFIP0BYRz6fHtwH/ocJaAbj7U9/g8UND57R1tbexdFEnV/V0sXRRJ8sWdbF0URdX9Uw+Xraok2U9XSxLj69c2ElbW6MOpJmZNauygIqIcUl3A48A7cD9EbFf0p3p9a3AHwAPSHqSYkjwAxFxVNLLgB3F3Ak6gE9GxMNV1VozfHqc16xexr963csYGh7l+PAYx4dHOX6qeDw0PMq3j5zk+KlRhkbGOHO2ce+qTbB00WSgLat97ym3TQZbra2z3R9LMzOrqXSpo4jYBeyqa9taenyYondUf95B4Poqa2skgKuvWMCbXvHiCx579mzw/OlxhoZHOXZqlKFamA2PpUCbbBs4PsK+7z/H8eFRTo+fnfI9Fy/oYGlPJ1eVemZFb23ycRF0kyHX3dU+h1fAzCwfl9VafBcrIlCTI3NtbWJJdydLujt56Yt6mv4ZI6NnOJZ6ZZOhNsrxU2Mp1CZ7bgePnmTo1BjPn5565v2CjrY0/FjuqU09/Lh0URdXLuxAzf6iZmYt4oAqCUANJx/One6udlZ0dbNiaXfT54yOn2VoJAXaqdLQ43C5rWh/+ofPMZSGI6cYgaSjTSyd6JFN9saWpmC7qjY82TP5+pLuTjo8BGlm88gBVVYkVHa6Otq4ZvFCrlm8sOlzzp4NnvvJ2ESYFUORY6mHdu5Q5LPHhnl8YIjjp8YYPTP1EOSVCzvO6Y2VJ4wsrbuvtiyF3MJOD0Ga2ew4oEoyzadZaWtTmqjRxRqaG4KMCIZHz0z0zI7V3Usr996OnhzlWz86ydDwKKdGz0z5nt2d7XUzIDsbDEmWA6+TKxZ4CNLMHFDnKO5BvXD/MEqiZ0EHPQs6WLms+fNOj5/hxPBYurc2NuUMyOPDo3x/aITjw6OcGBljqo+YdbbrvOHHZamXNjH8WDdZ5MruTto9td/ssuKAKrmcelDzaUFHO9dc2c41VzY/BHnmbPDcSBFqQ6VJIrXhx1rbsTRZ5PizRdvYmcapJsGS7k6Wdp97b21Jaap/eep/7R5cT1f7C/o/JWY5c0CVRND0LD67OO1tKob2erqaPiciODV65pxJIbVp/seHxzgxfO4QZP/ghWdBdrW3pRDrZGl3KcB6iufLSpNJyt+7OjxhxKxqDqiSINyDypgkrljQwRULOlh11aKmzxs7c5ah4TFOjExODhkaHmNo5Nze2tBIacLI8Bij03xmraer/ZweWS3kahNHlnZ3TgxLLkvPPQxpNjMOqJKiB+U/IJebzvY2li9ewPLFC5o+JyL4ydjZc6bzDw2f+1m1odK9tcNDIwyNTD+9vzYMWZu238ww5LJFXSzyMKS9QDmgSiJ8D8oKkujuaqe7q5ufmsFn1s6eDZ7/yXgRZCOlQDs1NhFgtV7b0ZPF0llDw2OcbHYYstY7K31urXzfzcOQdjlxQNVzQtlFaGsTSxZ1smRR54zOqw1DlgOsvHzWiZHJiSTf+/HshiGLiSHnrjIy+YHtIuiWdHuhY8uHA6okIipfScKskdkOQ46MnWkcaKUJI7XgO1ya4j/TYcjJoCsFWinwPAxpVXBAlQSexWeXDkks6upgUVfHjJbOKg9DTgTYyLmfYasNRw6ePM23fnSSEyMzG4acmBXZYBhyWc/kcw9D2nQcUCW+B2UvBOVhyNVNrjICk2tCnhg+dwmtofR8qBR4zxwd5vjwEEPD0y+f1Wg2ZBFek724cu9tSXfR5mB7YXBAlQTNr2Zu9kIzmzUhy8OQ503vL60yUuuxHT4xwonUg5tqvzU4N9iWpt5a+fNstaCr9daWpHYH26XFAVVS9KCcUGZzZbbDkBHFfmsnytP7R4p7a0MpwI4Pj06E2TdPPDfR3kywLSn30kq9tqWl4cha+C3p7mRBhxc9bgUHVInvQZnlQRJXLuzkyoWdrLqq+fMigpOnxyc+t1bbpmZopOixFT21yQ9tf/OHz3EitY1PE2yLutobBFdpJmT35OfZlqbAW7LIwXaxHFAlXurI7NImicULO1l8EcFWC6z6Xlttuv/Q8NjESv4XCrbuzvbi3tlEz6wUctP02hxshUoDStJ64KNAO/CxiPjDuteXAB8Hrku1/JeI+F/NnFsNLxdr9kJ0TrDN4Lza+pBDw6Pn9dpOjKT7bqVeW+2D2UPDoxcMttrw4rIpem1Lus/9jNuS7stv/7XKAkpSO7AFuBUYAHZL2hkRT5UOuwt4KiLeJmk5cEDSJ4AzTZw759yDMrOZKK8POZMtaur3Xiv32k6MjJ0zO/LEyCj9R05OTCSZakV/gIWdbaXZj2nB457JMDu/F5f3xqJV9qDWAf0RcRBA0nZgA1AOmQAWq/iE3xXAMWAceG0T584595/MbD7Mdu+1WrANlULsnHttpUkkJ4bH+M7gSYYusFUNFMFWC6tyr602+7G+17bqqkVcsaD6O0RV/oQVwKHS8wGK4Cm7D9gJHAYWA3dExFlJzZwLgKRNwCaA66677qIKLjYsvKi3MDOrTDnYZjorcmTszGQvbeLD2Of32oaGxzh49OTE40afY9vyrht5yytfMpe/WkNVBlSjP/X1Ef4mYC/wBuCngc9J+nKT5xaNEduAbQC9vb1T/xehCUUPygllZpeX8nT/mSx+XA62ck/tVdctrbDaSVUG1ACcc79xJUVPqezdwB9GRAD9kr4L/HyT584534MyM5s022CbK1V+rHo3sFbSGkldwEaK4byyZ4E3Aki6Fvg54GCT5865YrFYMzPLQWU9qIgYl3Q38AjFVPH7I2K/pDvT61uBPwAekPQkxbDeByLiKECjc6uqdaJmvGGhmVkuKp2GERG7gF11bVtLjw8DtzV7buUu6g6WmZnNJa+cWOKljszM8uGAKvGGhWZm+XBAlbgHZWaWDwdUiTcsNDPLhwOqxBsWmpnlwwFVUnxQ1wllZpYDB1SJF4s1M8uHA6rMCWVmlg0HVEngaeZmZrlwQJV4sVgzs3w4oEo8wmdmlg8HVIk3LDQzy4cDqsQbFpqZ5cMBVRIBbc4nM7MsOKDqeYzPzCwLDqik2HXekyTMzHLhgEpSPrkDZWaWCQdUUttM15MkzMzyUGlASVov6YCkfkmbG7z+fkl709c+SWckXZVee0bSk+m1virrhNIQn/PJzCwLHVW9saR2YAtwKzAA7Ja0MyKeqh0TEfcC96bj3wb8TkQcK73NLRFxtKoayyZ7UGZmloMqe1DrgP6IOBgRo8B2YMM0x78T+FSF9UzL96DMzPJSZUCtAA6Vng+ktvNIWgSsBz5dag7gUUl7JG2a6odI2iSpT1Lf4ODgrIsNakN8TigzsxxUGVCN/tJHgzaAtwF/Vze8d1NE3AjcDtwl6fWNToyIbRHRGxG9y5cvn3WxMVVlZmbWElUG1ACwqvR8JXB4imM3Uje8FxGH0/cjwA6KIcPKuQNlZpaHKgNqN7BW0hpJXRQhtLP+IElLgF8BHiq19UhaXHsM3Absq7DWyXtQniZhZpaFymbxRcS4pLuBR4B24P6I2C/pzvT61nTo24FHI+JU6fRrgR3pflAH8MmIeLiqWqF8D6rKn2JmZs2qLKAAImIXsKuubWvd8weAB+raDgLXV1lbvckelJmZ5cArSSQTn4NyQpmZZcEBlUwuFuuEMjPLgQMqcQ/KzCwvDqjEn4MyM8uLA6pmYqkjd6HMzHLggEomppm3uA4zMys4oBIvFmtmlhcHVOLtNszM8uKASiY3LHREmZnlwAGVeJq5mVleHFCJlzoyM8uLAyoJPEvCzCwnDqga96DMzLLigEp8D8rMLC8OqMQbFpqZ5cUBlXjDQjOzvDigEs/iMzPLS6UBJWm9pAOS+iVtbvD6+yXtTV/7JJ2RdFUz584134MyM8tLZQElqR3YAtwOvBx4p6SXl4+JiHsj4oaIuAG4B/hSRBxr5ty55g0LzczyUmUPah3QHxEHI2IU2A5smOb4dwKfmuW5Fy28GJ+ZWVaqDKgVwKHS84HUdh5Ji4D1wKdnce4mSX2S+gYHBy+6aOeTmVkeqgyoRn/rp9q39m3A30XEsZmeGxHbIqI3InqXL18+izJr75N+sG9CmZllocqAGgBWlZ6vBA5PcexGJof3ZnrunPCGhWZmeakyoHYDayWtkdRFEUI76w+StAT4FeChmZ47l7xhoZlZXjqqeuOIGJd0N/AI0A7cHxH7Jd2ZXt+aDn078GhEnLrQuVXVCp5mbmaWm8oCCiAidgG76tq21j1/AHigmXOr5GnmZmZ58UoSiXtQZmZ5cUAlMdX8QjMzawkH1ITaYrHuQpmZ5cABlXixWDOzvDigEt+DMjPLiwMq8YaFZmZ5cUAl3rDQzCwvDqjE96DMzPLigEq81JGZWV4cUEngDaHMzHLigErcgzIzy4sDqo7zycwsDw6oxBsWmpnlxQGVeMNCM7O8OKAS34MyM8tLUwEl6S+aabuUeakjM7O8NNuDekX5iaR24NVzX07reMNCM7O8TBtQku6R9DzwSknPpa/ngSPAQ/NS4TyZ2A7K+WRmloVpAyoi/lNELAbujYgr09fiiHhRRNxzoTeXtF7SAUn9kjZPcczNkvZK2i/pS6X2ZyQ9mV7rm/FvNkNe6sjMLC8dTR73WUk9EXFK0q8DNwIfjYjvTXVCGgbcAtwKDAC7Je2MiKdKxywF/hhYHxHPSrqm7m1uiYijM/mFZs8bFpqZ5aTZe1B/AgxLuh74PeB7wJ9f4Jx1QH9EHIyIUWA7sKHumHcBn4mIZwEi4kjTlc8x96DMzPLSbECNRzGLYANFz+mjwOILnLMCOFR6PpDayn4WWCbpi5L2SPqN0msBPJraN031QyRtktQnqW9wcLDJX+d8nsVnZpaXZof4npd0D/AvgNel4bvOC5zT6E991D3voJgN+EagG/iKpL+PiG8BN0XE4TTs9zlJ34yIx857w4htwDaA3t7e+vdvmjcsNDPLS7M9qDuA08C/jIgfUvSE7r3AOQPAqtLzlcDhBsc8HBGn0r2mx4DrASLicPp+BNhBMWRYmYlp5s4nM7MsNBVQKZQ+ASyR9FbgJxFxoXtQu4G1ktZI6gI2AjvrjnmIokfWIWkR8FrgaUk9khYDSOoBbgP2Nf1bzYI32zAzy0uzK0n8KvA14J8Dvwp8VdI7pjsnIsaBu4FHgKeB/x0R+yXdKenOdMzTwMPAE+n9PxYR+4Brgb+V9Hhq/6uIeHg2v2CzwgllZpaVZu9BfRB4TW2WnaTlwP8F/nK6kyJiF7Crrm1r3fN7qRsujIiDpKG++TK5WKwTyswsB83eg2qrmwL+4xmce2nwYrFmZllptgf1sKRHgE+l53dQ1zO61HmEz8wsL9MGlKSfAa6NiPdL+qfAL1P8Df8KxaSJy4Y3LDQzy8uFhuk+AjwPEBGfiYjfjYjfoeg9faTq4ubTxD0o55OZWRYuFFCrI+KJ+saI6ANWV1JRi3ipIzOzvFwooBZO81r3XBbSal7qyMwsLxcKqN2S/nV9o6T3AHuqKak1wh+EMjPLyoVm8f02sEPSrzEZSL1AF/D2Kgubb+5BmZnlZdqAiogfAb8k6RbgF1LzX0XE31Re2XzzPSgzs6w09TmoiPgC8IWKa2mp8IaFZmZZubxWg7gInsVnZpYXB1QSXurIzCwrDqhkcg6fE8rMLAcOqMQbFpqZ5cUBlcx6r3gzM6uEAyrxPSgzs7w4oCZ4w0Izs5xUGlCS1ks6IKlf0uYpjrlZ0l5J+yV9aSbnziX3oMzM8tLshoUzJqkd2ALcCgxQrOu3MyKeKh2zFPhjYH1EPCvpmmbPnWte6sjMLC9V9qDWAf0RcTAiRoHtwIa6Y94FfCYingUobSvfzLlzavKDuk4oM7McVBlQK4BDpecDqa3sZ4Flkr4oaY+k35jBuQBI2iSpT1Lf4ODgrIv1hoVmZnmpbIiPxqsG1c/m7gBeDbyRYn+pr0j6+ybPLRojtgHbAHp7e2c9W9xLHZmZ5aXKgBoAVpWerwQONzjmaEScAk5Jegy4vslz55TvQZmZ5aXKIb7dwFpJayR1ARuBnXXHPAS8TlKHpEXAa4Gnmzx3TnnDQjOzvFTWg4qIcUl3A48A7cD9EbFf0p3p9a0R8bSkh4EngLPAxyJiH0Cjc6uqtcw9KDOzPFQ5xEdE7AJ21bVtrXt+L3BvM+dWyfegzMzy4pUkEm9YaGaWFwdU4h6UmVleHFCJlzoyM8uLAyrxhoVmZnlxQCXesNDMLC8OqMQbFpqZ5cUBVeN7UGZmWXFAJZ5mbmaWFwdU4mnmZmZ5cUAlXizWzCwvDqjEGxaameXFAZV4w0Izs7w4oBLfgzIzy4sDKpn4HJQTyswsCw6omtpKEk4oM7MsOKASz+IzM8uLAyrxPSgzs7w4oJLJxWIdUWZmOag0oCStl3RAUr+kzQ1ev1nSCUl709eHSq89I+nJ1N5XZZ1Q3m7DzMxy0FHVG0tqB7YAtwIDwG5JOyPiqbpDvxwRb53ibW6JiKNV1VjmDQvNzPJSZQ9qHdAfEQcjYhTYDmyo8OddFG9YaGaWlyoDagVwqPR8ILXV+0VJj0v6a0mvKLUH8KikPZI2TfVDJG2S1Cepb3BwcNbFhmdJmJllpbIhPhr/qa/fF/DrwEsj4qSkNwMPAmvTazdFxGFJ1wCfk/TNiHjsvDeM2AZsA+jt7b3ofQc9xGdmlocqe1ADwKrS85XA4fIBEfFcRJxMj3cBnZKuTs8Pp+9HgB0UQ4aVcQfKzCwvVQbUbmCtpDWSuoCNwM7yAZJerDSvW9K6VM+PJfVIWpzae4DbgH0V1uoNC83MMlPZEF9EjEu6G3gEaAfuj4j9ku5Mr28F3gG8V9I4MAJsjIiQdC2wI4VFB/DJiHi4qlqLeorvjiczszxUeQ+qNmy3q65ta+nxfcB9Dc47CFxfZW3n/cz03R0oM7M8eCWJxBsWmpnlxQGVeMNCM7O8OKCSuOgJ6mZmNpccUHXcgzIzy4MDKglvWGhmlhUHVOLFYs3M8uKASrzdhplZXhxQyWQPyhFlZpYDB1QyMc28xXWYmVnBAZX4HpSZWV4cUMnkUkdOKDOzHDigavxJXTOzrDigksDDe2ZmOXFAJRGeIGFmlhMHVBKE7z+ZmWXEAZW4B2VmlhcHVOJ7UGZmeak0oCStl3RAUr+kzQ1ev1nSCUl709eHmj13rhU9KCeUmVkuKtvyXVI7sAW4FRgAdkvaGRFP1R365Yh46yzPnTOBx/jMzHJSZQ9qHdAfEQcjYhTYDmyYh3Nnx/lkZpaVKgNqBXCo9HwgtdX7RUmPS/prSa+Y4blI2iSpT1Lf4ODgrIv1PSgzs7xUGVCN/tzXL9fwdeClEXE98D+AB2dwbtEYsS0ieiOid/ny5bMuNiJ8D8rMLCNVBtQAsKr0fCVwuHxARDwXESfT411Ap6Srmzl3rkW4B2VmlpMqA2o3sFbSGkldwEZgZ/kASS9W+nSspHWpnh83c+5cC3wPyswsJ5XN4ouIcUl3A48A7cD9EbFf0p3p9a3AO4D3ShoHRoCNERFAw3OrqrWoxyuZm5nlpLKAgolhu111bVtLj+8D7mv23CoF4R6UmVlGvJJEEh7jMzPLigOqxPlkZpYPB1QS4dXMzcxy4oBK/EFdM7O8OKASb7dhZpYXB1TiDQvNzPLigErcgzIzy4sDKvE9KDOzvDigkghwH8rMLB8OqAnhHpSZWUYcUInvQZmZ5cUBlXi7DTOzvDigkmKxWCeUmVkuHFCJe1BmZnlxQCVezNzMLC8OqMQbFpqZ5cUBlQTR6hLMzKzEAVXje1BmZlmpNKAkrZd0QFK/pM3THPcaSWckvaPU9oykJyXtldRXZZ3gpY7MzHLTUdUbS2oHtgC3AgPAbkk7I+KpBsd9GHikwdvcEhFHq6qxLMLTzM3MclJlD2od0B8RByNiFNgObGhw3L8FPg0cqbCWC3IPyswsL1UG1ArgUOn5QGqbIGkF8HZga4PzA3hU0h5Jm6b6IZI2SeqT1Dc4ODjrYr3UkZlZXqoMqEZ/7+unyn0E+EBEnGlw7E0RcSNwO3CXpNc3+iERsS0ieiOid/ny5bMutuhBOaLMzHJR2T0oih7TqtLzlcDhumN6ge0pGK4G3ixpPCIejIjDABFxRNIOiiHDx6oq9qN33OCJ5mZmGamyB7UbWCtpjaQuYCOws3xARKyJiNURsRr4S+DfRMSDknokLQaQ1APcBuyrsFba2kR7m3tQZma5qKwHFRHjku6mmJ3XDtwfEfsl3Zleb3TfqeZaYEfqWXUAn4yIh6uq1czM8qOIy2dgq7e3N/r6Kv/IlJmZXQRJeyKi90LHeSUJMzPLkgPKzMyy5IAyM7MsOaDMzCxLDigzM8uSA8rMzLJ0WU0zlzQIfO8i3uJqYF5WT79Il0KdrnHuXAp1Xgo1wqVR5wuhxpdGxAXXprusAupiSeprZm5+q10KdbrGuXMp1Hkp1AiXRp2ucZKH+MzMLEsOKDMzy5ID6lzbWl1Aky6FOl3j3LkU6rwUaoRLo07XmPgelJmZZck9KDMzy5IDyszMsuSASiStl3RAUr+kza2up0bSM5KelLRXUl9qu0rS5yR9O31fNs813S/piKR9pbYpa5J0T7quByS9qcV1/r6k76fruVfSm1tZp6RVkr4g6WlJ+yW9L7Vncz2nqTG3a7lQ0tckPZ7q/PepPadrOVWNWV3L9HPbJX1D0mfT8/m/jhHxgv+i2FDxO8DLgC7gceDlra4r1fYMcHVd238GNqfHm4EPz3NNrwduBPZdqCbg5el6LgDWpOvc3sI6fx/4dw2ObUmdwEuAG9PjxcC3Ui3ZXM9pasztWgq4Ij3uBL4K/MPMruVUNWZ1LdPP/l3gk8Bn0/N5v47uQRXWAf0RcTAiRoHtwIYW1zSdDcCfpcd/BvyT+fzhEfEYcKzJmjYA2yPidER8F+inuN6tqnMqLakzIn4QEV9Pj58HngZWkNH1nKbGqbTqWkZEnExPO9NXkNe1nKrGqbTkWkpaCbwF+FhdLfN6HR1QhRXAodLzAab/BzifAnhU0h5Jm1LbtRHxAyj+eADXtKy6SVPVlOO1vVvSE2kIsDZM0fI6Ja0GXkXxv+osr2ddjZDZtUzDUnuBI8DnIiK7azlFjZDXtfwI8HvA2VLbvF9HB1RBDdpymX9/U0TcCNwO3CXp9a0uaIZyu7Z/Avw0cAPwA+C/pvaW1inpCuDTwG9HxHPTHdqgbV7qbFBjdtcyIs5ExA3ASmCdpF+Y5vCW1DlFjdlcS0lvBY5ExJ5mT2nQNic1OqAKA8Cq0vOVwOEW1XKOiDicvh8BdlB0nX8k6SUA6fuR1lU4Yaqasrq2EfGj9AfiLPCnTA5FtKxOSZ0Uf/g/ERGfSc1ZXc9GNeZ4LWsiYgj4IrCezK5loxozu5Y3Af9Y0jMUtzveIOnjtOA6OqAKu4G1ktZI6gI2AjtbXBOSeiQtrj0GbgP2UdT2m+mw3wQeak2F55iqpp3ARkkLJK0B1gJfa0F9wMQ/rJq3U1xPaFGdkgT8T+DpiPhvpZeyuZ5T1ZjhtVwuaWl63A38I+Cb5HUtG9aY07WMiHsiYmVErKb4W/g3EfHrtOI6zsdskEvhC3gzxeyk7wAfbHU9qaaXUcyOeRzYX6sLeBHweeDb6ftV81zXpyiGIcYo/vf0nulqAj6YrusB4PYW1/kXwJPAE+kf1ktaWSfwyxTDIU8Ae9PXm3O6ntPUmNu1fCXwjVTPPuBDqT2nazlVjVldy9LPvpnJWXzzfh291JGZmWXJQ3xmZpYlB5SZmWXJAWVmZllyQJmZWZYcUGZmliUHlFmFJJ0prVC9V3O4Ur6k1Sqt1G52uelodQFml7mRKJa1MbMZcg/KrAVU7PP14bQ30Nck/Uxqf6mkz6dFQz8v6brUfq2kHWkfoccl/VJ6q3ZJf5r2Fno0rU6ApN+S9FR6n+0t+jXNLooDyqxa3XVDfHeUXnsuItYB91GsHk16/OcR8UrgE8AfpfY/Ar4UEddT7HG1P7WvBbZExCuAIeCfpfbNwKvS+9xZ1S9nViWvJGFWIUknI+KKBu3PAG+IiINpIdYfRsSLJB2lWOZmLLX/ICKuljQIrIyI06X3WE2xXcPa9PwDQGdE/EdJDwMngQeBB2NyDyKzS4Z7UGatE1M8nuqYRk6XHp9h8r7yW4AtwKuBPZJ8v9kuOQ4os9a5o/T9K+nx/6NYQRrg14C/TY93Z5ikAAAAoUlEQVQ/D7wXJja8u3KqN5XUBqyKiC9QbDq3FDivF2eWO/+vyqxa3Wn31JqHI6I21XyBpK9S/Efxnantt4D7Jb0fGATendrfB2yT9B6KntJ7KVZqb6Qd+LikJRSbyf33KPYeMruk+B6UWQuke1C9EXG01bWY5cpDfGZmliX3oMzMLEvuQZmZWZYcUGZmliUHlJmZZckBZWZmWXJAmZlZlv4/monPYzFcz+cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_two_layer_perceptron(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Numeric Feature Data\n",
    "Now normalize the continuous numeric feature data. Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Be sure that training converges by graphing the loss function versus the number of epochs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999997e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        4.49541421e-09, 0.00000000e+00, 4.59531231e-09],\n",
       "       [9.99999999e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        8.99082755e-09, 0.00000000e+00, 3.39653485e-09],\n",
       "       [9.99999999e-01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        4.79510755e-09, 6.99286517e-10, 4.69520947e-09],\n",
       "       ...,\n",
       "       [1.00000000e+00, 7.06823965e-10, 2.70672001e-08, ...,\n",
       "        1.10874347e-10, 0.00000000e+00, 3.18763749e-10],\n",
       "       [1.00000000e+00, 7.06823964e-10, 2.70672000e-08, ...,\n",
       "        2.63326575e-11, 0.00000000e+00, 4.08849156e-10],\n",
       "       [1.00000000e+00, 7.06823964e-10, 2.70672000e-08, ...,\n",
       "        6.92964670e-11, 0.00000000e+00, 2.48081352e-10]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize Continuous Numeric Feature Data\n",
    "from sklearn.preprocessing import Normalizer \n",
    "normalizer = Normalizer(norm = 'l2')\n",
    "\n",
    "normalizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 150/400"
     ]
    }
   ],
   "source": [
    "analyze_two_layer_perceptron(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Continuous Numeric Feature Data\n",
    "Now normalize the continuous numeric feature data AND one hot encode the categorical data. Use the example two-layer perceptron network from the class example and quantify performance using accuracy. Be sure that training converges by graphing the loss function versus the number of epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encode categorical data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_two_layer_perceptron(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare Performance\n",
    "Compare the performance of the three models you just trained. Are there any meaningful differences in performance? Explain, in your own words, why these models have (or do not have) different performances.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize and One-Code Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third Layer of Perceptron\n",
    "Add support for saving (and plotting after training is completed) the average magnitude of the gradient for each layer, for each epoch. For magnitude calculation, you are free to use either the average absolute values or the L1/L2 norm. Quantify the performance of the model and graph the magnitudes for each layer versus the number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth Layer of Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fifth Layer of Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaptive Learning\n",
    "Implement an adaptive learning technique that was discussed in lecture and use it on the five layer network. Compare the performance of this model with and without the adaptive learning strategy. Do not use AdaM for the adaptive learning technique. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
